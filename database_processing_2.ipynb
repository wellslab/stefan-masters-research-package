{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping PMIDs to cell line data\n",
    "def create_pmid_to_celllines_mapping(gt_data):\n",
    "    \"\"\"\n",
    "    Create a dictionary where:\n",
    "    - Keys: PMIDs (excluding \"Missing\")\n",
    "    - Values: List of cell line data objects that have publications with that PMID\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Get all unique PMIDs (excluding \"Missing\")\n",
    "    all_pmids = set()\n",
    "    \n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            for pub in cell_line_data['publications']:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid != \"Missing\" and pmid is not None:\n",
    "                        all_pmids.add(pmid)\n",
    "    \n",
    "    print(f\"Found {len(all_pmids)} unique PMIDs (excluding 'Missing')\")\n",
    "    \n",
    "    # Step 2: Create mapping from PMID to cell lines\n",
    "    pmid_to_celllines = {}\n",
    "    \n",
    "    for pmid in all_pmids:\n",
    "        pmid_to_celllines[pmid] = []\n",
    "        \n",
    "        # Find all cell lines that have this PMID\n",
    "        for cell_line_key, cell_line_data in gt_data.items():\n",
    "            if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "                # Check if this cell line has a publication with this PMID\n",
    "                has_pmid = False\n",
    "                for pub in cell_line_data['publications']:\n",
    "                    if isinstance(pub, dict) and 'pmid' in pub and pub['pmid'] == pmid:\n",
    "                        has_pmid = True\n",
    "                        break\n",
    "                \n",
    "                if has_pmid:\n",
    "                    # Add the entire cell line data object\n",
    "                    pmid_to_celllines[pmid].append({\n",
    "                        'cell_line_id': cell_line_key,\n",
    "                        'data': cell_line_data\n",
    "                    })\n",
    "    \n",
    "    # Step 3: Print summary statistics\n",
    "    print(f\"\\nPMID to Cell Lines Mapping Summary:\")\n",
    "    print(f\"Total unique PMIDs: {len(pmid_to_celllines)}\")\n",
    "    \n",
    "    # Show distribution of how many cell lines per PMID\n",
    "    cellline_counts = [len(cell_lines) for cell_lines in pmid_to_celllines.values()]\n",
    "    from collections import Counter\n",
    "    count_distribution = Counter(cellline_counts)\n",
    "    \n",
    "    print(f\"Distribution of cell lines per PMID:\")\n",
    "    for count, frequency in sorted(count_distribution.items()):\n",
    "        print(f\"  {count} cell line(s): {frequency} PMID(s)\")\n",
    "    \n",
    "    # Show examples of PMIDs with multiple cell lines\n",
    "    multi_cellline_pmids = {pmid: cell_lines for pmid, cell_lines in pmid_to_celllines.items() if len(cell_lines) > 1}\n",
    "    if multi_cellline_pmids:\n",
    "        print(f\"\\nExample PMIDs with multiple cell lines:\")\n",
    "        for pmid, cell_lines in list(multi_cellline_pmids.items())[:5]:\n",
    "            cell_line_ids = [cl['cell_line_id'] for cl in cell_lines]\n",
    "            print(f\"  PMID {pmid}: {cell_line_ids}\")\n",
    "    \n",
    "    return pmid_to_celllines\n",
    "\n",
    "# Create the mapping\n",
    "pmid_to_celllines = create_pmid_to_celllines_mapping(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping PMIDs to cell line data\n",
    "def create_pmid_to_celllines_mapping(gt_data):\n",
    "    \"\"\"\n",
    "    Create a dictionary where:\n",
    "    - Keys: PMIDs (excluding \"Missing\")\n",
    "    - Values: List of cell line data objects that have publications with that PMID\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Get all unique PMIDs (excluding \"Missing\")\n",
    "    all_pmids = set()\n",
    "    \n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            for pub in cell_line_data['publications']:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid != \"Missing\" and pmid is not None:\n",
    "                        all_pmids.add(pmid)\n",
    "    \n",
    "    print(f\"Found {len(all_pmids)} unique PMIDs (excluding 'Missing')\")\n",
    "    \n",
    "    # Step 2: Create mapping from PMID to cell lines\n",
    "    pmid_to_celllines = {}\n",
    "    \n",
    "    for pmid in all_pmids:\n",
    "        pmid_to_celllines[pmid] = []\n",
    "        \n",
    "        # Find all cell lines that have this PMID\n",
    "        for cell_line_key, cell_line_data in gt_data.items():\n",
    "            if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "                # Check if this cell line has a publication with this PMID\n",
    "                has_pmid = False\n",
    "                for pub in cell_line_data['publications']:\n",
    "                    if isinstance(pub, dict) and 'pmid' in pub and pub['pmid'] == pmid:\n",
    "                        has_pmid = True\n",
    "                        break\n",
    "                \n",
    "                if has_pmid:\n",
    "                    # Add the entire cell line data object\n",
    "                    pmid_to_celllines[pmid].append({\n",
    "                        'cell_line_id': cell_line_key,\n",
    "                        'data': cell_line_data\n",
    "                    })\n",
    "    \n",
    "    # Step 3: Print summary statistics\n",
    "    print(f\"\\nPMID to Cell Lines Mapping Summary:\")\n",
    "    print(f\"Total unique PMIDs: {len(pmid_to_celllines)}\")\n",
    "    \n",
    "    # Show distribution of how many cell lines per PMID\n",
    "    cellline_counts = [len(cell_lines) for cell_lines in pmid_to_celllines.values()]\n",
    "    from collections import Counter\n",
    "    count_distribution = Counter(cellline_counts)\n",
    "    \n",
    "    print(f\"Distribution of cell lines per PMID:\")\n",
    "    for count, frequency in sorted(count_distribution.items()):\n",
    "        print(f\"  {count} cell line(s): {frequency} PMID(s)\")\n",
    "    \n",
    "    # Show examples of PMIDs with multiple cell lines\n",
    "    multi_cellline_pmids = {pmid: cell_lines for pmid, cell_lines in pmid_to_celllines.items() if len(cell_lines) > 1}\n",
    "    if multi_cellline_pmids:\n",
    "        print(f\"\\nExample PMIDs with multiple cell lines:\")\n",
    "        for pmid, cell_lines in list(multi_cellline_pmids.items())[:5]:\n",
    "            cell_line_ids = [cl['cell_line_id'] for cl in cell_lines]\n",
    "            print(f\"  PMID {pmid}: {cell_line_ids}\")\n",
    "    \n",
    "    return pmid_to_celllines\n",
    "\n",
    "# Create the mapping\n",
    "pmid_to_celllines = create_pmid_to_celllines_mapping(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate publications based on PMID\n",
    "def remove_duplicate_publications(gt_data):\n",
    "    \"\"\"\n",
    "    Remove duplicate publication objects within each cell line's publications list\n",
    "    based on the pmid field.\n",
    "    \"\"\"\n",
    "    duplicates_found = 0\n",
    "    total_publications_before = 0\n",
    "    total_publications_after = 0\n",
    "    \n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        # Check if this cell line has publications\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            publications = cell_line_data['publications']\n",
    "            original_count = len(publications)\n",
    "            total_publications_before += original_count\n",
    "            \n",
    "            # Track seen PMIDs to identify duplicates\n",
    "            seen_pmids = set()\n",
    "            unique_publications = []\n",
    "            \n",
    "            for pub in publications:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid not in seen_pmids:\n",
    "                        seen_pmids.add(pmid)\n",
    "                        unique_publications.append(pub)\n",
    "                    else:\n",
    "                        print(f\"Duplicate PMID found in {cell_line_key}: {pmid}\")\n",
    "                        duplicates_found += 1\n",
    "                else:\n",
    "                    # Keep publications without PMID field\n",
    "                    unique_publications.append(pub)\n",
    "            \n",
    "            # Update the publications list\n",
    "            cell_line_data['publications'] = unique_publications\n",
    "            total_publications_after += len(unique_publications)\n",
    "            \n",
    "            # Report if duplicates were removed for this cell line\n",
    "            if len(unique_publications) < original_count:\n",
    "                print(f\"  Removed {original_count - len(unique_publications)} duplicate(s) from {cell_line_key}\")\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total duplicates found and removed: {duplicates_found}\")\n",
    "    print(f\"Total publications before: {total_publications_before}\")\n",
    "    print(f\"Total publications after: {total_publications_after}\")\n",
    "    print(f\"Publications reduced by: {total_publications_before - total_publications_after}\")\n",
    "    \n",
    "    return gt_data\n",
    "\n",
    "# Apply the deduplication\n",
    "ground_truth_data = remove_duplicate_publications(ground_truth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total files loaded: 315\n",
      "['VCCRIi013-A',\n",
      " 'MNZTASi002-A',\n",
      " 'MCRIi001-A-5',\n",
      " 'LEIi008-A',\n",
      " 'LEIi012-B',\n",
      " 'UQi004-A',\n",
      " 'UOWi007-A',\n",
      " 'VCCRIi029-A',\n",
      " 'MNZTASi020-B',\n",
      " 'AIBNi005-A']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "# Load all JSON files from ground_truth directory into a dictionary\n",
    "ground_truth_dir = Path(\"ground_truth\")\n",
    "gt_data = {}    \n",
    "\n",
    "# Read each JSON file and store with filename stem as key\n",
    "for json_file in ground_truth_dir.glob(\"*.json\"):\n",
    "    file_stem = json_file.stem.split(\"_\")[0]  # Gets filename without extension\n",
    "    try:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            gt_data[file_stem] = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {json_file}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal files loaded: {len(gt_data)}\")\n",
    "pprint(list(gt_data.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'basic_data': [{'cell_line_alt_name': 'GENIE 1',\n",
      "                 'cell_type': 'hiPSC',\n",
      "                 'frozen': 'True'}],\n",
      " 'contact': [{'e_mail': ' e.wolvetang@uq.edu.au',\n",
      "              'first_name': 'Ernst',\n",
      "              'group': 'Wolvetang-AIBN',\n",
      "              'last_name': 'Wolvetang',\n",
      "              'name_initials': 'J',\n",
      "              'phone_number': 'Missing'}],\n",
      " 'culture_medium': [{'co2_concentration': '0.05',\n",
      "                     'o2_concentration': 'Missing',\n",
      "                     'passage_method': 'EF'}],\n",
      " 'differentiation_results': [{'cell_type': 'EN',\n",
      "                              'description': '',\n",
      "                              'marker_list': 'FOXA2; SOX17',\n",
      "                              'method_used': 'RT-qPCR',\n",
      "                              'show_potency': 'True'},\n",
      "                             {'cell_type': 'ME',\n",
      "                              'description': '',\n",
      "                              'marker_list': 'HAND1; RUNX1',\n",
      "                              'method_used': 'RT-qPCR',\n",
      "                              'show_potency': 'True'},\n",
      "                             {'cell_type': 'EC',\n",
      "                              'description': '',\n",
      "                              'marker_list': 'NR2F2; PAX6',\n",
      "                              'method_used': 'RT-qPCR',\n",
      "                              'show_potency': 'True'}],\n",
      " 'donor': [{'age': '35_39',\n",
      "            'disease_description': 'nan',\n",
      "            'disease_name': 'Epilepsy',\n",
      "            'sex': 'F'}],\n",
      " 'embryonic_derivation': [{'e_preimplant_genetic_diagnosis': 'Missing',\n",
      "                           'embryo_stage': 'Missing',\n",
      "                           'icm_morphology': 'Missing',\n",
      "                           'trophectoderm_morphology': 'Missing',\n",
      "                           'zp_removal_technique': 'Missing'}],\n",
      " 'ethics': [{'approval_date': '2019-01-01',\n",
      "             'ethics_number': 'QRBW/54086',\n",
      "             'institutional_HREC': 'The University of Queensland Human Ethics '\n",
      "                                   'Research Office'}],\n",
      " 'generator': [{'group': 'Australian Institute for Bioengineering and '\n",
      "                         'Nanotechnology'}],\n",
      " 'genomic_characterisation': [{'karyotype': '46,XX',\n",
      "                               'karyotype_method': 'GB',\n",
      "                               'passage_number': '9',\n",
      "                               'summary': 'Karyotyping occurred at a '\n",
      "                                          'resolution of 300bphs. Fifteen '\n",
      "                                          'metaphase spreads were analysed.'}],\n",
      " 'genomic_modifications': [{'cytoband': 'Missing',\n",
      "                            'delivery_method': 'Missing',\n",
      "                            'description': 'Missing',\n",
      "                            'genotype': 'Missing',\n",
      "                            'loci_name': 'Missing',\n",
      "                            'mutation_type': 'Missing'}],\n",
      " 'induced_derivation': [{'derivation_year': '2020-01-01',\n",
      "                         'i_source_cell_origin_id': 'UBERON:0000178',\n",
      "                         'i_source_cell_origin_term': 'blood',\n",
      "                         'i_source_cell_type_id': 'CL:2000001',\n",
      "                         'i_source_cell_type_term': 'peripheral blood '\n",
      "                                                    'mononuclear cell',\n",
      "                         'non_int_vector': 'SV',\n",
      "                         'non_int_vector_name': '[kit] CytoTune-iPS 2.0 Sendai '\n",
      "                                                'reprogramming kit'}],\n",
      " 'publications': [{'doi': '10.1016/j.scr.2021.102564',\n",
      "                   'first_author': 'Hunter ZL',\n",
      "                   'journal': 'Stem cell research',\n",
      "                   'last_author': 'Vadlamudi L',\n",
      "                   'pmid': '34649201',\n",
      "                   'title': 'Generation of induced pluripotent stem cell lines '\n",
      "                            'from peripheral blood mononuclear cells of three '\n",
      "                            'drug resistant and three drug responsive epilepsy '\n",
      "                            'patients',\n",
      "                   'year': '2021'},\n",
      "                  {'doi': 'https://doi.org/10.1016/j.scr.2021.102564',\n",
      "                   'first_author': 'Zoe L Hunter',\n",
      "                   'journal': 'Stem Cell Research',\n",
      "                   'last_author': 'Lata Vadlamudi',\n",
      "                   'pmid': '34649201',\n",
      "                   'title': 'Generation of induced pluripotent stem cell lines '\n",
      "                            'from peripheral blood mononuclear cells of three '\n",
      "                            'drug resistant and three drug responsive epilepsy '\n",
      "                            'patients.',\n",
      "                   'year': '2021'}],\n",
      " 'undifferentiated_characterisation': [{'epi_pluri_score': 'Missing',\n",
      "                                        'pluri_novelty_score': 'Missing',\n",
      "                                        'pluri_test_score': 'Missing'}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(gt_data[\"AIBNi001-A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate PMID found in LEIi008-A: 30611018\n",
      "  Removed 1 duplicate(s) from LEIi008-A\n",
      "Duplicate PMID found in LEIi012-B: 32810830\n",
      "  Removed 1 duplicate(s) from LEIi012-B\n",
      "Duplicate PMID found in UOWi007-A: 32006803\n",
      "  Removed 1 duplicate(s) from UOWi007-A\n",
      "Duplicate PMID found in AIBNi005-A: 34649201\n",
      "  Removed 1 duplicate(s) from AIBNi005-A\n",
      "Duplicate PMID found in HPIi004-B: 35728440\n",
      "  Removed 1 duplicate(s) from HPIi004-B\n",
      "Duplicate PMID found in MCRIi001-A: Missing\n",
      "Duplicate PMID found in MCRIi001-A: Missing\n",
      "Duplicate PMID found in MCRIi001-A: Missing\n",
      "Duplicate PMID found in MCRIi001-A: Missing\n",
      "Duplicate PMID found in MCRIi001-A: Missing\n",
      "  Removed 5 duplicate(s) from MCRIi001-A\n",
      "Duplicate PMID found in GENEAe012-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe012-A\n",
      "Duplicate PMID found in MCRIi019-A: 33002832\n",
      "Duplicate PMID found in MCRIi019-A: 33316599\n",
      "Duplicate PMID found in MCRIi019-A: 34543885\n",
      "  Removed 3 duplicate(s) from MCRIi019-A\n",
      "Duplicate PMID found in MCRIi001-A-4: 32771907\n",
      "  Removed 1 duplicate(s) from MCRIi001-A-4\n",
      "Duplicate PMID found in LEIi018-A: 34214897\n",
      "  Removed 1 duplicate(s) from LEIi018-A\n",
      "Duplicate PMID found in MCRIi017-A: 31415975\n",
      "  Removed 1 duplicate(s) from MCRIi017-A\n",
      "Duplicate PMID found in GENEAe008-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe008-A\n",
      "Duplicate PMID found in UQi001-A-1: 37315423\n",
      "  Removed 1 duplicate(s) from UQi001-A-1\n",
      "Duplicate PMID found in AIBNi010-A: 35074713\n",
      "  Removed 1 duplicate(s) from AIBNi010-A\n",
      "Duplicate PMID found in AIBNi006-A: 34649201\n",
      "  Removed 1 duplicate(s) from AIBNi006-A\n",
      "Duplicate PMID found in MCRIi020-A: 33091851\n",
      "  Removed 1 duplicate(s) from MCRIi020-A\n",
      "Duplicate PMID found in MCRIi012-A: 31415975\n",
      "  Removed 1 duplicate(s) from MCRIi012-A\n",
      "Duplicate PMID found in GENEAe010-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe010-A\n",
      "Duplicate PMID found in AIBNi007-A: 35074713\n",
      "  Removed 1 duplicate(s) from AIBNi007-A\n",
      "Duplicate PMID found in AIBNi012-A: 35074713\n",
      "  Removed 1 duplicate(s) from AIBNi012-A\n",
      "Duplicate PMID found in LEIi012-A: 32810830\n",
      "  Removed 1 duplicate(s) from LEIi012-A\n",
      "Duplicate PMID found in HPIi002-B: 34388489\n",
      "  Removed 1 duplicate(s) from HPIi002-B\n",
      "Duplicate PMID found in AIBNi011-A: 35074713\n",
      "  Removed 1 duplicate(s) from AIBNi011-A\n",
      "Duplicate PMID found in MCRIi019-A-7: 34543885\n",
      "  Removed 1 duplicate(s) from MCRIi019-A-7\n",
      "Duplicate PMID found in MCRIi018-A: 31082677\n",
      "  Removed 1 duplicate(s) from MCRIi018-A\n",
      "Duplicate PMID found in GENEAe005-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe005-A\n",
      "Duplicate PMID found in SCSe001-A-2: 29499499\n",
      "  Removed 1 duplicate(s) from SCSe001-A-2\n",
      "Duplicate PMID found in MCRIi015-A: 31415975\n",
      "  Removed 1 duplicate(s) from MCRIi015-A\n",
      "Duplicate PMID found in GENEAe009-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe009-A\n",
      "Duplicate PMID found in AIBNi009-A: 35074713\n",
      "  Removed 1 duplicate(s) from AIBNi009-A\n",
      "Duplicate PMID found in GENEAe002-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe002-A\n",
      "Duplicate PMID found in MCRIi019-A-2: 33002832\n",
      "  Removed 1 duplicate(s) from MCRIi019-A-2\n",
      "Duplicate PMID found in MCRIi011-A: 31415975\n",
      "  Removed 1 duplicate(s) from MCRIi011-A\n",
      "Duplicate PMID found in AIBNi004-A: 34649201\n",
      "  Removed 1 duplicate(s) from AIBNi004-A\n",
      "Duplicate PMID found in AIBNi008-A: 35074713\n",
      "  Removed 1 duplicate(s) from AIBNi008-A\n",
      "Duplicate PMID found in MCRIi013-A: 31415975\n",
      "  Removed 1 duplicate(s) from MCRIi013-A\n",
      "Duplicate PMID found in LEIi011-C: 31494449\n",
      "  Removed 1 duplicate(s) from LEIi011-C\n",
      "Duplicate PMID found in MCRIi023-A: 33091851\n",
      "  Removed 1 duplicate(s) from MCRIi023-A\n",
      "Duplicate PMID found in AIBNi014-A: 34507142\n",
      "Duplicate PMID found in AIBNi014-A: 34459078\n",
      "  Removed 2 duplicate(s) from AIBNi014-A\n",
      "Duplicate PMID found in MCRIi019-A-6: 36682125\n",
      "  Removed 1 duplicate(s) from MCRIi019-A-6\n",
      "Duplicate PMID found in AIBNi003-A: 34649201\n",
      "  Removed 1 duplicate(s) from AIBNi003-A\n",
      "Duplicate PMID found in LEIi017-A: 34198153\n",
      "  Removed 1 duplicate(s) from LEIi017-A\n",
      "Duplicate PMID found in HPIi004-A: 35728440\n",
      "  Removed 1 duplicate(s) from HPIi004-A\n",
      "Duplicate PMID found in GENEAe004-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe004-A\n",
      "Duplicate PMID found in UOWi001-A: 30278375\n",
      "  Removed 1 duplicate(s) from UOWi001-A\n",
      "Duplicate PMID found in GENEAe003-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe003-A\n",
      "Duplicate PMID found in UOWi002-A: 30138848\n",
      "  Removed 1 duplicate(s) from UOWi002-A\n",
      "Duplicate PMID found in MCRIi001-A-3: 32771907\n",
      "  Removed 1 duplicate(s) from MCRIi001-A-3\n",
      "Duplicate PMID found in LEIi016-B: 34034222\n",
      "  Removed 1 duplicate(s) from LEIi016-B\n",
      "Duplicate PMID found in MCRIi024-A: 34157503\n",
      "  Removed 1 duplicate(s) from MCRIi024-A\n",
      "Duplicate PMID found in HPIi002-A: 34388489\n",
      "  Removed 1 duplicate(s) from HPIi002-A\n",
      "Duplicate PMID found in HPIi001-B: 33740643\n",
      "  Removed 1 duplicate(s) from HPIi001-B\n",
      "Duplicate PMID found in HPIi003-A: 35728439\n",
      "  Removed 1 duplicate(s) from HPIi003-A\n",
      "Duplicate PMID found in GENEAe007-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe007-A\n",
      "Duplicate PMID found in LEIi011-B: 31494449\n",
      "  Removed 1 duplicate(s) from LEIi011-B\n",
      "Duplicate PMID found in LEIi009-A: 30611018\n",
      "  Removed 1 duplicate(s) from LEIi009-A\n",
      "Duplicate PMID found in MCRIi016-A: 31415975\n",
      "  Removed 1 duplicate(s) from MCRIi016-A\n",
      "Duplicate PMID found in LEIi005-B: 31059986\n",
      "  Removed 1 duplicate(s) from LEIi005-B\n",
      "Duplicate PMID found in LEIi015-A: 33429167\n",
      "  Removed 1 duplicate(s) from LEIi015-A\n",
      "Duplicate PMID found in GENEAe011-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe011-A\n",
      "Duplicate PMID found in MCRIi024-A-1: 34157503\n",
      "  Removed 1 duplicate(s) from MCRIi024-A-1\n",
      "Duplicate PMID found in LEIi010-B: 30904819\n",
      "  Removed 1 duplicate(s) from LEIi010-B\n",
      "Duplicate PMID found in MCRIi018-B: 31082677\n",
      "  Removed 1 duplicate(s) from MCRIi018-B\n",
      "Duplicate PMID found in AIBNi002-A: 34649201\n",
      "  Removed 1 duplicate(s) from AIBNi002-A\n",
      "Duplicate PMID found in MCRIi010-A-1: 38277710\n",
      "  Removed 1 duplicate(s) from MCRIi010-A-1\n",
      "Duplicate PMID found in LEIi011-A: 31494449\n",
      "  Removed 1 duplicate(s) from LEIi011-A\n",
      "Duplicate PMID found in HPIi007-A: 38583293\n",
      "  Removed 1 duplicate(s) from HPIi007-A\n",
      "Duplicate PMID found in MCRIi001-A-1: Missing\n",
      "Duplicate PMID found in MCRIi001-A-1: Missing\n",
      "Duplicate PMID found in MCRIi001-A-1: Missing\n",
      "Duplicate PMID found in MCRIi001-A-1: Missing\n",
      "Duplicate PMID found in MCRIi001-A-1: Missing\n",
      "  Removed 5 duplicate(s) from MCRIi001-A-1\n",
      "Duplicate PMID found in LEIi014-C: 33360097\n",
      "  Removed 1 duplicate(s) from LEIi014-C\n",
      "Duplicate PMID found in LEIi015-B: 33429167\n",
      "  Removed 1 duplicate(s) from LEIi015-B\n",
      "Duplicate PMID found in HPIi001-A: 33740643\n",
      "  Removed 1 duplicate(s) from HPIi001-A\n",
      "Duplicate PMID found in LEIi010-A: 30904819\n",
      "  Removed 1 duplicate(s) from LEIi010-A\n",
      "Duplicate PMID found in SCSe001-A-1: 29499499\n",
      "  Removed 1 duplicate(s) from SCSe001-A-1\n",
      "Duplicate PMID found in VCCRIi001-A: 31707208\n",
      "  Removed 1 duplicate(s) from VCCRIi001-A\n",
      "Duplicate PMID found in LEIi014-A: 33360097\n",
      "  Removed 1 duplicate(s) from LEIi014-A\n",
      "Duplicate PMID found in AIBNi001-A: 34649201\n",
      "  Removed 1 duplicate(s) from AIBNi001-A\n",
      "Duplicate PMID found in MCRIi022-A: 33091851\n",
      "  Removed 1 duplicate(s) from MCRIi022-A\n",
      "Duplicate PMID found in MCRIi001-B: 32446218\n",
      "  Removed 1 duplicate(s) from MCRIi001-B\n",
      "Duplicate PMID found in MCRIi021-A: 33091851\n",
      "  Removed 1 duplicate(s) from MCRIi021-A\n",
      "Duplicate PMID found in LEIi014-B: 33360097\n",
      "  Removed 1 duplicate(s) from LEIi014-B\n",
      "Duplicate PMID found in UOWi005-A: Missing\n",
      "Duplicate PMID found in UOWi005-A: Missing\n",
      "Duplicate PMID found in UOWi005-A: Missing\n",
      "Duplicate PMID found in UOWi005-A: 31445393\n",
      "  Removed 4 duplicate(s) from UOWi005-A\n",
      "Duplicate PMID found in UOWi003-A: 30138848\n",
      "  Removed 1 duplicate(s) from UOWi003-A\n",
      "Duplicate PMID found in MCRIi014-A: 31415975\n",
      "  Removed 1 duplicate(s) from MCRIi014-A\n",
      "Duplicate PMID found in AIBNi013-A: 34507143\n",
      "  Removed 1 duplicate(s) from AIBNi013-A\n",
      "Duplicate PMID found in LEIi007-A: 30634128\n",
      "  Removed 1 duplicate(s) from LEIi007-A\n",
      "Duplicate PMID found in LEIi016-A: 34034222\n",
      "  Removed 1 duplicate(s) from LEIi016-A\n",
      "Duplicate PMID found in MCRIi019-A-1: 33316599\n",
      "  Removed 1 duplicate(s) from MCRIi019-A-1\n",
      "Duplicate PMID found in GENEAe006-A: 18386991\n",
      "  Removed 1 duplicate(s) from GENEAe006-A\n",
      "Duplicate PMID found in LEIi017-B: 34198153\n",
      "  Removed 1 duplicate(s) from LEIi017-B\n",
      "Duplicate PMID found in FINi003-A: 38479087\n",
      "  Removed 1 duplicate(s) from FINi003-A\n",
      "\n",
      "Summary:\n",
      "Total duplicates found and removed: 104\n",
      "Total publications before: 525\n",
      "Total publications after: 421\n",
      "Publications reduced by: 104\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate publications based on PMID\n",
    "def remove_duplicate_publications(gt_data):\n",
    "    \"\"\"\n",
    "    Remove duplicate publication objects within each cell line's publications list\n",
    "    based on the pmid field.\n",
    "    \"\"\"\n",
    "    duplicates_found = 0\n",
    "    total_publications_before = 0\n",
    "    total_publications_after = 0\n",
    "    \n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        # Check if this cell line has publications\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            publications = cell_line_data['publications']\n",
    "            original_count = len(publications)\n",
    "            total_publications_before += original_count\n",
    "            \n",
    "            # Track seen PMIDs to identify duplicates\n",
    "            seen_pmids = set()\n",
    "            unique_publications = []\n",
    "            \n",
    "            for pub in publications:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid not in seen_pmids:\n",
    "                        seen_pmids.add(pmid)\n",
    "                        unique_publications.append(pub)\n",
    "                    else:\n",
    "                        print(f\"Duplicate PMID found in {cell_line_key}: {pmid}\")\n",
    "                        duplicates_found += 1\n",
    "                else:\n",
    "                    # Keep publications without PMID field\n",
    "                    unique_publications.append(pub)\n",
    "            \n",
    "            # Update the publications list\n",
    "            cell_line_data['publications'] = unique_publications\n",
    "            total_publications_after += len(unique_publications)\n",
    "            \n",
    "            # Report if duplicates were removed for this cell line\n",
    "            if len(unique_publications) < original_count:\n",
    "                print(f\"  Removed {original_count - len(unique_publications)} duplicate(s) from {cell_line_key}\")\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total duplicates found and removed: {duplicates_found}\")\n",
    "    print(f\"Total publications before: {total_publications_before}\")\n",
    "    print(f\"Total publications after: {total_publications_after}\")\n",
    "    print(f\"Publications reduced by: {total_publications_before - total_publications_after}\")\n",
    "    \n",
    "    return gt_data\n",
    "\n",
    "# Apply the deduplication\n",
    "gt_data = remove_duplicate_publications(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCCRIi013-A\n",
      "MCRIi001-A-5\n",
      "UQi004-A\n",
      "VCCRIi029-A\n",
      "MNZTASi020-B\n",
      "MNZTASi025-A\n",
      "MUCCSi003-A\n",
      "ESIBIe003-A\n",
      "MCRIi028-A-1\n",
      "MCRIi019-A-4\n",
      "VCCRIi028-A\n",
      "FINi005-A\n",
      "UOWi004-A\n",
      "MCRIi028-A\n",
      "MNZTASi024-A\n",
      "VCCRIi031-A\n",
      "MNZTASi032-A\n",
      "MUCCSi004-A\n",
      "VCCRIi014-A\n",
      "MNZTASi023-A\n",
      "VCCRIi012-A\n",
      "MNZTASi020-A\n",
      "MCRIi031-A-3\n",
      "MNZTASi030-A\n",
      "UQi008-A\n",
      "UTSWi003-A-3\n",
      "VCCRIi004-A\n",
      "UQi009-A\n",
      "MNZTASi014-A\n",
      "VCCRIi027-A\n",
      "UOMELBi001-A-4\n",
      "MNZTASi029-A\n",
      "MCRIi019-A-3\n",
      "MUCCSi002-A\n",
      "LEIi020-A\n",
      "VCCRIi035-A\n",
      "MCRIi033-A\n",
      "VCCRIi036-A\n",
      "VCCRIi025-A\n",
      "WIMRi001-A\n",
      "VCCRIi017-A\n",
      "MNZTASi011-A\n",
      "UOWi009-A\n",
      "VCCRIi009-A\n",
      "UOWi003-A-1\n",
      "UTSWi001-A-2\n",
      "WIMRi003-A\n",
      "MUCCSi001-A\n",
      "VCCRIi006-A\n",
      "VCCRIi030-A\n",
      "VCCRIi019-A\n",
      "HPIi011-A\n",
      "CIAUi002-A\n",
      "FINi006-A\n",
      "VCCRIi011-A\n",
      "MNZTASi016-A\n",
      "MNZTASi010-A\n",
      "VCCRIi018-A\n",
      "UTSWi002-A-2\n",
      "UQi003-A\n",
      "FINi004-A\n",
      "UTSWi002-A-3\n",
      "MNZTASi034-B\n",
      "MCRIi031-A\n",
      "UOMELBi001-A-2\n",
      "MNZTASi015-C\n",
      "UOMELBi001-A\n",
      "UTSWi003-A-2\n",
      "SCSe001-A\n",
      "MCRIi010-A-2\n",
      "MNZTASi028-A\n",
      "MNZTASi017-A\n",
      "WIMRi004-A\n",
      "UOMELBi001-A-3\n",
      "VCCRIi032-A\n",
      "MNZTASi009-B\n",
      "LEIi019-A\n",
      "VCCRIi008-A\n",
      "MNZTASi034-A\n",
      "MNZTASi015-B\n",
      "MCRIi001-D\n",
      "MNZTASi018-A\n",
      "MNZTASi015-A\n",
      "UOMELBi004-A\n",
      "SCSe001-A-5\n",
      "MCRIi029-A\n",
      "MNZTASi032-C\n",
      "VCCRIi010-A\n",
      "VCCRIi021-A\n",
      "UTSWi002-A\n",
      "VCCRIi020-A\n",
      "MNZTASi008-A\n",
      "MCRIi031-A-2\n",
      "MNZTASi012-A\n",
      "VCCRIi022-A\n",
      "MNZTASi009-A\n",
      "MNZTASi026-A\n",
      "HPIi010-A\n",
      "VCCRIi015-A\n",
      "VCCRIi007-A\n",
      "UQi002-A\n",
      "MNZTASi031-A\n",
      "MNZTASi006-A\n",
      "UOMELBi001-A-1\n",
      "MNZTASi033-A\n",
      "CIAUi003-A-1\n",
      "VCCRIi024-A\n",
      "FINi002-A-1\n",
      "UQi005-A\n",
      "UTSWi001-A-3\n",
      "MCRIi032-A\n",
      "VCCRIi034-A\n",
      "UQi007-A\n",
      "MNZTASi013-A\n",
      "WIMRi002-A\n",
      "VCCRIi016-A\n",
      "AIBNe001-A\n",
      "UTSWi001-A\n",
      "HPIi012-A\n",
      "VCCRIi033-A\n",
      "MCRIi010-A-3\n",
      "VCCRIi026-A\n",
      "CIAUi002-B\n",
      "VCCRIi005-A\n",
      "UQi006-A\n",
      "MNZTASi027-A\n",
      "MCRIi001-C\n",
      "MNZTASi034-C\n",
      "LEIi020-B\n",
      "WAe009-A\n",
      "CIAUi001-A\n",
      "UOWi009-A-1\n",
      "VCCRIi023-A\n",
      "UTSWi003-A\n",
      "MNZTASi007-A\n",
      "MNZTASi032-B\n",
      "UOWi010-A\n",
      "MCRIi031-A-1\n"
     ]
    }
   ],
   "source": [
    "for cell_line_key, cell_line_data in gt_data.items():\n",
    "    if len(cell_line_data[\"publications\"]) == 1 and cell_line_data['publications'][0]['pmid'] == \"Missing\":\n",
    "        print(cell_line_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 115 unique PMIDs (excluding 'Missing')\n",
      "\n",
      "PMID to Cell Lines Mapping Summary:\n",
      "Total unique PMIDs: 115\n",
      "Distribution of cell lines per PMID:\n",
      "  1 cell line(s): 45 PMID(s)\n",
      "  2 cell line(s): 37 PMID(s)\n",
      "  3 cell line(s): 11 PMID(s)\n",
      "  4 cell line(s): 8 PMID(s)\n",
      "  5 cell line(s): 5 PMID(s)\n",
      "  6 cell line(s): 4 PMID(s)\n",
      "  7 cell line(s): 2 PMID(s)\n",
      "  8 cell line(s): 1 PMID(s)\n",
      "  9 cell line(s): 1 PMID(s)\n",
      "  11 cell line(s): 1 PMID(s)\n",
      "\n",
      "Example PMIDs with multiple cell lines:\n",
      "  PMID 36355287: ['MCRIi001-A', 'MCRIi001-A-4', 'MCRIi001-A-3']\n",
      "  PMID 33497524: ['LEIi004-A', 'LEIi004-A-1']\n",
      "  PMID 33002832: ['MCRIi019-A', 'MCRIi019-A-2']\n",
      "  PMID 32446218: ['MCRIi001-A', 'MCRIi001-A-2', 'MCRIi001-B']\n",
      "  PMID 36166872: ['AIBNi015-A', 'AIBNi017-A', 'AIBNi016-A', 'AIBNi018-A']\n"
     ]
    }
   ],
   "source": [
    " # Create a dictionary mapping PMIDs to cell line data\n",
    "def create_pmid_to_celllines_mapping(gt_data):\n",
    "    \"\"\"\n",
    "    Create a dictionary where:\n",
    "    - Keys: PMIDs (excluding \"Missing\")\n",
    "    - Values: List of cell line data objects that have publications with that PMID\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Get all unique PMIDs (excluding \"Missing\")\n",
    "    all_pmids = set()\n",
    "\n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            for pub in cell_line_data['publications']:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid != \"Missing\" and pmid is not None:\n",
    "                        all_pmids.add(pmid)\n",
    "\n",
    "    print(f\"Found {len(all_pmids)} unique PMIDs (excluding 'Missing')\")\n",
    "\n",
    "    # Step 2: Create mapping from PMID to cell lines\n",
    "    pmid_to_celllines = {}\n",
    "\n",
    "    for pmid in all_pmids:\n",
    "        pmid_to_celllines[pmid] = []\n",
    "\n",
    "        # Find all cell lines that have this PMID\n",
    "        for cell_line_key, cell_line_data in gt_data.items():\n",
    "            if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "                # Check if this cell line has a publication with this PMID\n",
    "                has_pmid = False\n",
    "                for pub in cell_line_data['publications']:\n",
    "                    if isinstance(pub, dict) and 'pmid' in pub and pub['pmid'] == pmid:\n",
    "                        has_pmid = True\n",
    "                        break\n",
    "\n",
    "                if has_pmid:\n",
    "                    # Add the entire cell line data object\n",
    "                    pmid_to_celllines[pmid].append({\n",
    "                        'cell_line_id': cell_line_key,\n",
    "                        'data': cell_line_data\n",
    "                    })\n",
    "\n",
    "    # Step 3: Print summary statistics\n",
    "    print(f\"\\nPMID to Cell Lines Mapping Summary:\")\n",
    "    print(f\"Total unique PMIDs: {len(pmid_to_celllines)}\")\n",
    "\n",
    "    # Show distribution of how many cell lines per PMID\n",
    "    cellline_counts = [len(cell_lines) for cell_lines in pmid_to_celllines.values()]\n",
    "    from collections import Counter\n",
    "    count_distribution = Counter(cellline_counts)\n",
    "\n",
    "    print(f\"Distribution of cell lines per PMID:\")\n",
    "    for count, frequency in sorted(count_distribution.items()):\n",
    "        print(f\"  {count} cell line(s): {frequency} PMID(s)\")\n",
    "\n",
    "    # Show examples of PMIDs with multiple cell lines\n",
    "    multi_cellline_pmids = {pmid: cell_lines for pmid, cell_lines in pmid_to_celllines.items() if len(cell_lines) > 1}\n",
    "    if multi_cellline_pmids:\n",
    "        print(f\"\\nExample PMIDs with multiple cell lines:\")\n",
    "        for pmid, cell_lines in list(multi_cellline_pmids.items())[:5]:\n",
    "            cell_line_ids = [cl['cell_line_id'] for cl in cell_lines]\n",
    "            print(f\"  PMID {pmid}: {cell_line_ids}\")\n",
    "\n",
    "    return pmid_to_celllines\n",
    "\n",
    "# Create the mapping\n",
    "pmid_to_celllines = create_pmid_to_celllines_mapping(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell lines journals lists\n",
    "\n",
    "# It gives a list of cell lines and journals they are published in, where we have the journal information\n",
    "# So we are excluding cell lines which don't have journal information. \n",
    "# I need to know and want to report on which journal it came from.\n",
    "cell_line_journals = dict()\n",
    "\n",
    "for cell_line_key, cell_line_data in gt_data.items():\n",
    "    journals = []\n",
    "    for pub in cell_line_data[\"publications\"]:\n",
    "        if \"journal\" in pub and pub[\"journal\"] != \"Missing\":\n",
    "            journals.append(pub[\"journal\"])\n",
    "    cell_line_journals[cell_line_key] = journals\n",
    "\n",
    "\n",
    "# Should include the hypothesis about structured reporting increases the performance of the curation process.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# Cell lines which appear in more than one journal\n",
    "\n",
    "more_than_one_journal = [cell_line for cell_line, journals in cell_line_journals.items() if len(journals) > 1]\n",
    "\n",
    "print(len(more_than_one_journal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "8\n",
      "['Stem cell research & therapy',\n",
      " 'Cells',\n",
      " 'Stem cell research',\n",
      " 'Cloning and stem cells',\n",
      " 'Stem cell reports',\n",
      " 'Stem cells and development',\n",
      " 'In vitro cellular & developmental biology. Animal',\n",
      " 'Molecular genetics & genomic medicine']\n"
     ]
    }
   ],
   "source": [
    "# Cell lines which appear in exactly one journal\n",
    "exactly_one_journal = [cell_line for cell_line, journals in cell_line_journals.items() if len(journals) == 1]   \n",
    "print(len(exactly_one_journal))\n",
    " \n",
    "\n",
    "# Get the set of unique journal names for cell lines that appear in exactly one journal, ignoring case\n",
    "unique_journals = set()\n",
    "journal_name_map = dict()  # maps lowercased journal name to original for display\n",
    "\n",
    "for cell_line in exactly_one_journal:\n",
    "    journals = cell_line_journals[cell_line]\n",
    "    if journals:  # should always be length 1, but check anyway\n",
    "        journal_lower = journals[0].lower()\n",
    "        unique_journals.add(journal_lower)\n",
    "        # Store the first encountered original-case version for display\n",
    "        if journal_lower not in journal_name_map:\n",
    "            journal_name_map[journal_lower] = journals[0]\n",
    "\n",
    "print(len(unique_journals))\n",
    "\n",
    "# Display the unique journals in their original case (first encountered)\n",
    "from pprint import pprint\n",
    "pprint([journal_name_map[j] for j in unique_journals])\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Count how many cell lines are associated with each journal (for cell lines in exactly one journal), ignoring case\n",
    "journal_counts = Counter()\n",
    "for cell_line in exactly_one_journal:\n",
    "    journals = cell_line_journals[cell_line]\n",
    "    if journals:  # should always be length 1\n",
    "        journal_lower = journals[0].lower()\n",
    "        journal_counts[journal_lower] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem cell research: 113\n",
      "stem cells and development: 8\n",
      "cloning and stem cells: 11\n",
      "molecular genetics & genomic medicine: 1\n",
      "stem cell reports: 1\n",
      "stem cell research & therapy: 3\n",
      "cells: 2\n",
      "in vitro cellular & developmental biology. animal: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the counts\n",
    "for journal, count in journal_counts.items():\n",
    "    print(f\"{journal}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "113 cell lines from SCR\n",
    "28 cell lines from non-SCR\n",
    "\n",
    "\n",
    "Why did you only take cell lines which were associated with exactly one journal?\n",
    "Because I could not tell which journal article the data in the registry was associated with. So i needed to be sure that the data was from a specific publication, from a specific journal. So that I could run the automated curation on this publication and be sure that I had the right ground truth to compare my results to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MNZTASi002-A',\n",
      " 'LEIi008-A',\n",
      " 'LEIi012-B',\n",
      " 'UOWi007-A',\n",
      " 'AIBNi005-A',\n",
      " 'AIBNi015-A',\n",
      " 'HPIi004-B',\n",
      " 'POWHe001-A',\n",
      " 'MCRIi030-A-2',\n",
      " 'MCRIi019-A-5',\n",
      " 'GENEAe012-A',\n",
      " 'LEIi018-A',\n",
      " 'MCRIi027-B',\n",
      " 'MCRIi017-A',\n",
      " 'MCRIi009-A',\n",
      " 'GENEAe008-A',\n",
      " 'MNZTASi005-A',\n",
      " 'MONUi001-C',\n",
      " 'MCRIi025-B',\n",
      " 'ESIBIe003-A-10',\n",
      " 'UQi001-A-1',\n",
      " 'MONUi003-A',\n",
      " 'AIBNi010-A',\n",
      " 'MONUi001-A',\n",
      " 'AIBNi006-A',\n",
      " 'MCRIi020-A',\n",
      " 'LEIi005-A',\n",
      " 'MCRIi012-A',\n",
      " 'GENEAe010-A',\n",
      " 'AIBNi007-A',\n",
      " 'AIBNi012-A',\n",
      " 'LEIi012-A',\n",
      " 'HPIi002-B',\n",
      " 'AIBNi011-A',\n",
      " 'MCRIi030-A',\n",
      " 'CIAUi002-C',\n",
      " 'GENEAe005-A',\n",
      " 'SCSe001-A-2',\n",
      " 'MCRIi015-A',\n",
      " 'GENEAe009-A',\n",
      " 'VCCRIi003-A',\n",
      " 'AIBNi009-A',\n",
      " 'GENEAe002-A',\n",
      " 'HPIi009-A',\n",
      " 'WAe009-A-24',\n",
      " 'MNZTASi022-A',\n",
      " 'MCRIi011-A',\n",
      " 'POWHe001-A-4',\n",
      " 'AIBNi004-A',\n",
      " 'MCRIi003-A',\n",
      " 'AIBNi008-A',\n",
      " 'MCRIi013-A',\n",
      " 'LEIi011-C',\n",
      " 'MCRIi008-A',\n",
      " 'MCRIi023-A',\n",
      " 'MNZTASi021-A',\n",
      " 'CIAUi003-A',\n",
      " 'MCRIi019-A-6',\n",
      " 'AIBNi003-A',\n",
      " 'LEIi017-A',\n",
      " 'HPIi004-A',\n",
      " 'GENEAe004-A',\n",
      " 'AIBNi017-A',\n",
      " 'GENEAe003-A',\n",
      " 'UOCi002-A',\n",
      " 'MONUi002-B',\n",
      " 'POWHe001-A-2',\n",
      " 'VCCRIi002-A',\n",
      " 'MCRIi024-A',\n",
      " 'HPIi002-A',\n",
      " 'HPIi001-B',\n",
      " 'HPIi003-A',\n",
      " 'GENEAe007-A',\n",
      " 'LEIi011-B',\n",
      " 'MONUi002-C',\n",
      " 'MICCNi001-B',\n",
      " 'MCRIi005-A',\n",
      " 'LEIi009-A',\n",
      " 'UOWi008-A',\n",
      " 'MCRIi016-A',\n",
      " 'HPIi008-A',\n",
      " 'LEIi005-B',\n",
      " 'LEIi015-A',\n",
      " 'GENEAe011-A',\n",
      " 'MICCNi002-B',\n",
      " 'MCRIi024-A-1',\n",
      " 'MCRIi026-B',\n",
      " 'MNZTASi003-A',\n",
      " 'UOWi006-A',\n",
      " 'AIBNi002-A',\n",
      " 'MCRIi010-A-1',\n",
      " 'LEIi011-A',\n",
      " 'HPIi007-A',\n",
      " 'MCRIi026-A',\n",
      " 'LEIi014-C',\n",
      " 'HPIi006-A',\n",
      " 'MICCNi001-A',\n",
      " 'MCRIi007-A',\n",
      " 'ESIBIe003-A-2',\n",
      " 'UOCi001-A',\n",
      " 'LEIi015-B',\n",
      " 'WAe009-A-W',\n",
      " 'HPIi001-A',\n",
      " 'MONUi002-A',\n",
      " 'ESIBIe003-A-3',\n",
      " 'MONUi001-B',\n",
      " 'MONUi003-C',\n",
      " 'UOMELBi002-A',\n",
      " 'LEIi010-A',\n",
      " 'MCRIi025-A',\n",
      " 'MCRIi002-A',\n",
      " 'POWHe001-A-1',\n",
      " 'SCSe001-A-1',\n",
      " 'AIBNi016-A',\n",
      " 'HPIi005-B',\n",
      " 'ESIBIe003-A-1',\n",
      " 'POWHe002-A',\n",
      " 'MONUi003-B',\n",
      " 'LEIi014-A',\n",
      " 'AIBNi001-A',\n",
      " 'MCRIi022-A',\n",
      " 'MNZTASi004-A',\n",
      " 'MCRIi021-A',\n",
      " 'POWHe001-A-3',\n",
      " 'LEIi014-B',\n",
      " 'UQi001-A',\n",
      " 'MCRIi027-A',\n",
      " 'MCRIi014-A',\n",
      " 'AIBNi013-A',\n",
      " 'HPIi005-A',\n",
      " 'AIBNe001-A',\n",
      " 'LEIi007-A',\n",
      " 'MCRIi019-A-1',\n",
      " 'GENEAe006-A',\n",
      " 'MCRIi030-A-1',\n",
      " 'LEIi017-B',\n",
      " 'FINi003-A',\n",
      " 'GENEAe001-A',\n",
      " 'AIBNi018-A',\n",
      " 'MCRIi006-A',\n",
      " 'MNZTASi019-A']\n"
     ]
    }
   ],
   "source": [
    "pprint(exactly_one_journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35679759',\n",
      " '30611018',\n",
      " '32810830',\n",
      " '32006803',\n",
      " '34649201',\n",
      " '36166872',\n",
      " '35728440',\n",
      " '18271699',\n",
      " '38458031',\n",
      " '36682125',\n",
      " '18386991',\n",
      " '34214897',\n",
      " '36805468',\n",
      " '31415975',\n",
      " '37150143',\n",
      " '18386991',\n",
      " '35679759',\n",
      " '37494850',\n",
      " '36805468',\n",
      " '34619644',\n",
      " '37315423',\n",
      " '37494850',\n",
      " '35074713',\n",
      " '37494850',\n",
      " '34649201',\n",
      " '33091851',\n",
      " '32931148',\n",
      " '31415975',\n",
      " '18386991',\n",
      " '35074713',\n",
      " '35074713',\n",
      " '32810830',\n",
      " '34388489',\n",
      " '35074713',\n",
      " '38458031',\n",
      " '37385135',\n",
      " '18386991',\n",
      " '29499499',\n",
      " '31415975',\n",
      " '18386991',\n",
      " '37939621',\n",
      " '35074713',\n",
      " '18386991',\n",
      " '38582058',\n",
      " '32442534',\n",
      " '38433209',\n",
      " '31415975',\n",
      " '18271699',\n",
      " '34649201',\n",
      " '37150143',\n",
      " '35074713',\n",
      " '31415975',\n",
      " '31494449',\n",
      " '37150143',\n",
      " '33091851',\n",
      " '38433209',\n",
      " '31039485',\n",
      " '36682125',\n",
      " '34649201',\n",
      " '34198153',\n",
      " '35728440',\n",
      " '18386991',\n",
      " '36166872',\n",
      " '18386991',\n",
      " '35917601',\n",
      " '37494850',\n",
      " '18271699',\n",
      " '37939621',\n",
      " '34157503',\n",
      " '34388489',\n",
      " '33740643',\n",
      " '35728439',\n",
      " '18386991',\n",
      " '31494449',\n",
      " '37494850',\n",
      " '30622032',\n",
      " '30605840',\n",
      " '30611018',\n",
      " '32887382',\n",
      " '31415975',\n",
      " '38582058',\n",
      " '31059986',\n",
      " '33429167',\n",
      " '18386991',\n",
      " '30622032',\n",
      " '34157503',\n",
      " '36805468',\n",
      " '35679759',\n",
      " '32887382',\n",
      " '34649201',\n",
      " '38277710',\n",
      " '31494449',\n",
      " '38583293',\n",
      " '36805468',\n",
      " '33360097',\n",
      " '38583293',\n",
      " '30622032',\n",
      " '37150143',\n",
      " '16522163',\n",
      " '35917601',\n",
      " '33429167',\n",
      " '38244534',\n",
      " '33740643',\n",
      " '37494850',\n",
      " '16522163',\n",
      " '37494850',\n",
      " '37494850',\n",
      " '34088002',\n",
      " '30904819',\n",
      " '36805468',\n",
      " '37150143',\n",
      " '18271699',\n",
      " '29499499',\n",
      " '36166872',\n",
      " '38029555',\n",
      " '16522163',\n",
      " '20178001',\n",
      " '37494850',\n",
      " '33360097',\n",
      " '34649201',\n",
      " '33091851',\n",
      " '35679759',\n",
      " '33091851',\n",
      " '18271699',\n",
      " '33360097',\n",
      " '37315423',\n",
      " '36805468',\n",
      " '31415975',\n",
      " '34507143',\n",
      " '38029555',\n",
      " '30634128',\n",
      " '33316599',\n",
      " '18386991',\n",
      " '38458031',\n",
      " '34198153',\n",
      " '38479087',\n",
      " '20198447',\n",
      " '36166872',\n",
      " '30605840',\n",
      " '38433209']\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "ground_truth_pmids = [] \n",
    "for cell_line in exactly_one_journal:\n",
    "    pmid = gt_data[cell_line][\"publications\"][0][\"pmid\"]\n",
    "    if pmid != \"Missing\":\n",
    "        ground_truth_pmids.append(pmid)\n",
    "\n",
    "pprint(ground_truth_pmids)\n",
    "print(len(ground_truth_pmids))\n",
    "\n",
    "\n",
    "# These are the pmids I need to run the automated curation on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright. I got the files I need to curate. Now I need to curate them.\n",
    "\n",
    "# Test 1. Curate a single file.\n",
    "\n",
    "\n",
    "# Test 2. Curate every file.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Things to watch out for.\n",
    "- When batch curating. I need a report of the curation session.\n",
    "- Professional logging. To a loglife.\n",
    "- Let's do it.\n",
    "\n",
    "\n",
    "What needs to be written in the report about this. \n",
    "- Report on the curation instructions and how they were used.\n",
    "\n",
    "Also need to write the scoring function next. Tomorrow. After everything is done.\n",
    "Also need to write the nature news essay. But I don't particularly care about the marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stefan-masters-research",
   "language": "python",
   "name": "stefan-masters-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
