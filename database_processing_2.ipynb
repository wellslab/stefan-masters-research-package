{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pmid_to_celllines\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Create the mapping\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m pmid_to_celllines = create_pmid_to_celllines_mapping(\u001b[43mgt_data\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'gt_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping PMIDs to cell line data\n",
    "def create_pmid_to_celllines_mapping(gt_data):\n",
    "    \"\"\"\n",
    "    Create a dictionary where:\n",
    "    - Keys: PMIDs (excluding \"Missing\")\n",
    "    - Values: List of cell line data objects that have publications with that PMID\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Get all unique PMIDs (excluding \"Missing\")\n",
    "    all_pmids = set()\n",
    "    \n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            for pub in cell_line_data['publications']:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid != \"Missing\" and pmid is not None:\n",
    "                        all_pmids.add(pmid)\n",
    "    \n",
    "    print(f\"Found {len(all_pmids)} unique PMIDs (excluding 'Missing')\")\n",
    "    \n",
    "    # Step 2: Create mapping from PMID to cell lines\n",
    "    pmid_to_celllines = {}\n",
    "    \n",
    "    for pmid in all_pmids:\n",
    "        pmid_to_celllines[pmid] = []\n",
    "        \n",
    "        # Find all cell lines that have this PMID\n",
    "        for cell_line_key, cell_line_data in gt_data.items():\n",
    "            if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "                # Check if this cell line has a publication with this PMID\n",
    "                has_pmid = False\n",
    "                for pub in cell_line_data['publications']:\n",
    "                    if isinstance(pub, dict) and 'pmid' in pub and pub['pmid'] == pmid:\n",
    "                        has_pmid = True\n",
    "                        break\n",
    "                \n",
    "                if has_pmid:\n",
    "                    # Add the entire cell line data object\n",
    "                    pmid_to_celllines[pmid].append({\n",
    "                        'cell_line_id': cell_line_key,\n",
    "                        'data': cell_line_data\n",
    "                    })\n",
    "    \n",
    "    # Step 3: Print summary statistics\n",
    "    print(f\"\\nPMID to Cell Lines Mapping Summary:\")\n",
    "    print(f\"Total unique PMIDs: {len(pmid_to_celllines)}\")\n",
    "    \n",
    "    # Show distribution of how many cell lines per PMID\n",
    "    cellline_counts = [len(cell_lines) for cell_lines in pmid_to_celllines.values()]\n",
    "    from collections import Counter\n",
    "    count_distribution = Counter(cellline_counts)\n",
    "    \n",
    "    print(f\"Distribution of cell lines per PMID:\")\n",
    "    for count, frequency in sorted(count_distribution.items()):\n",
    "        print(f\"  {count} cell line(s): {frequency} PMID(s)\")\n",
    "    \n",
    "    # Show examples of PMIDs with multiple cell lines\n",
    "    multi_cellline_pmids = {pmid: cell_lines for pmid, cell_lines in pmid_to_celllines.items() if len(cell_lines) > 1}\n",
    "    if multi_cellline_pmids:\n",
    "        print(f\"\\nExample PMIDs with multiple cell lines:\")\n",
    "        for pmid, cell_lines in list(multi_cellline_pmids.items())[:5]:\n",
    "            cell_line_ids = [cl['cell_line_id'] for cl in cell_lines]\n",
    "            print(f\"  PMID {pmid}: {cell_line_ids}\")\n",
    "    \n",
    "    return pmid_to_celllines\n",
    "\n",
    "\n",
    "# Create the mapping\n",
    "pmid_to_celllines = create_pmid_to_celllines_mapping(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping PMIDs to cell line data\n",
    "def create_pmid_to_celllines_mapping(gt_data):\n",
    "    \"\"\"\n",
    "    Create a dictionary where:\n",
    "    - Keys: PMIDs (excluding \"Missing\")\n",
    "    - Values: List of cell line data objects that have publications with that PMID\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Get all unique PMIDs (excluding \"Missing\")\n",
    "    all_pmids = set()\n",
    "    \n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            for pub in cell_line_data['publications']:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid != \"Missing\" and pmid is not None:\n",
    "                        all_pmids.add(pmid)\n",
    "    \n",
    "    print(f\"Found {len(all_pmids)} unique PMIDs (excluding 'Missing')\")\n",
    "    \n",
    "    # Step 2: Create mapping from PMID to cell lines\n",
    "    pmid_to_celllines = {}\n",
    "    \n",
    "    for pmid in all_pmids:\n",
    "        pmid_to_celllines[pmid] = []\n",
    "        \n",
    "        # Find all cell lines that have this PMID\n",
    "        for cell_line_key, cell_line_data in gt_data.items():\n",
    "            if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "                # Check if this cell line has a publication with this PMID\n",
    "                has_pmid = False\n",
    "                for pub in cell_line_data['publications']:\n",
    "                    if isinstance(pub, dict) and 'pmid' in pub and pub['pmid'] == pmid:\n",
    "                        has_pmid = True\n",
    "                        break\n",
    "                \n",
    "                if has_pmid:\n",
    "                    # Add the entire cell line data object\n",
    "                    pmid_to_celllines[pmid].append({\n",
    "                        'cell_line_id': cell_line_key,\n",
    "                        'data': cell_line_data\n",
    "                    })\n",
    "    \n",
    "    # Step 3: Print summary statistics\n",
    "    print(f\"\\nPMID to Cell Lines Mapping Summary:\")\n",
    "    print(f\"Total unique PMIDs: {len(pmid_to_celllines)}\")\n",
    "    \n",
    "    # Show distribution of how many cell lines per PMID\n",
    "    cellline_counts = [len(cell_lines) for cell_lines in pmid_to_celllines.values()]\n",
    "    from collections import Counter\n",
    "    count_distribution = Counter(cellline_counts)\n",
    "    \n",
    "    print(f\"Distribution of cell lines per PMID:\")\n",
    "    for count, frequency in sorted(count_distribution.items()):\n",
    "        print(f\"  {count} cell line(s): {frequency} PMID(s)\")\n",
    "    \n",
    "    # Show examples of PMIDs with multiple cell lines\n",
    "    multi_cellline_pmids = {pmid: cell_lines for pmid, cell_lines in pmid_to_celllines.items() if len(cell_lines) > 1}\n",
    "    if multi_cellline_pmids:\n",
    "        print(f\"\\nExample PMIDs with multiple cell lines:\")\n",
    "        for pmid, cell_lines in list(multi_cellline_pmids.items())[:5]:\n",
    "            cell_line_ids = [cl['cell_line_id'] for cl in cell_lines]\n",
    "            print(f\"  PMID {pmid}: {cell_line_ids}\")\n",
    "    \n",
    "    return pmid_to_celllines\n",
    "\n",
    "# Create the mapping\n",
    "pmid_to_celllines = create_pmid_to_celllines_mapping(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate publications based on PMID\n",
    "def remove_duplicate_publications(gt_data):\n",
    "    \"\"\"\n",
    "    Remove duplicate publication objects within each cell line's publications list\n",
    "    based on the pmid field.\n",
    "    \"\"\"\n",
    "    duplicates_found = 0\n",
    "    total_publications_before = 0\n",
    "    total_publications_after = 0\n",
    "    \n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        # Check if this cell line has publications\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            publications = cell_line_data['publications']\n",
    "            original_count = len(publications)\n",
    "            total_publications_before += original_count\n",
    "            \n",
    "            # Track seen PMIDs to identify duplicates\n",
    "            seen_pmids = set()\n",
    "            unique_publications = []\n",
    "            \n",
    "            for pub in publications:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid not in seen_pmids:\n",
    "                        seen_pmids.add(pmid)\n",
    "                        unique_publications.append(pub)\n",
    "                    else:\n",
    "                        print(f\"Duplicate PMID found in {cell_line_key}: {pmid}\")\n",
    "                        duplicates_found += 1\n",
    "                else:\n",
    "                    # Keep publications without PMID field\n",
    "                    unique_publications.append(pub)\n",
    "            \n",
    "            # Update the publications list\n",
    "            cell_line_data['publications'] = unique_publications\n",
    "            total_publications_after += len(unique_publications)\n",
    "            \n",
    "            # Report if duplicates were removed for this cell line\n",
    "            if len(unique_publications) < original_count:\n",
    "                print(f\"  Removed {original_count - len(unique_publications)} duplicate(s) from {cell_line_key}\")\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total duplicates found and removed: {duplicates_found}\")\n",
    "    print(f\"Total publications before: {total_publications_before}\")\n",
    "    print(f\"Total publications after: {total_publications_after}\")\n",
    "    print(f\"Publications reduced by: {total_publications_before - total_publications_after}\")\n",
    "    \n",
    "    return gt_data\n",
    "\n",
    "# Apply the deduplication\n",
    "ground_truth_data = remove_duplicate_publications(ground_truth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "# Load all JSON files from ground_truth directory into a dictionary\n",
    "ground_truth_dir = Path(\"ground_truth\")\n",
    "gt_data = {}    \n",
    "\n",
    "# Read each JSON file and store with filename stem as key\n",
    "for json_file in ground_truth_dir.glob(\"*.json\"):\n",
    "    file_stem = json_file.stem.split(\"_\")[0]  # Gets filename without extension\n",
    "    try:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            gt_data[file_stem] = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {json_file}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal files loaded: {len(gt_data)}\")\n",
    "pprint(list(gt_data.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(gt_data[\"AIBNi001-A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate publications based on PMID\n",
    "def remove_duplicate_publications(gt_data):\n",
    "    \"\"\"\n",
    "    Remove duplicate publication objects within each cell line's publications list\n",
    "    based on the pmid field.\n",
    "    \"\"\"\n",
    "    duplicates_found = 0\n",
    "    total_publications_before = 0\n",
    "    total_publications_after = 0\n",
    "    \n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        # Check if this cell line has publications\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            publications = cell_line_data['publications']\n",
    "            original_count = len(publications)\n",
    "            total_publications_before += original_count\n",
    "            \n",
    "            # Track seen PMIDs to identify duplicates\n",
    "            seen_pmids = set()\n",
    "            unique_publications = []\n",
    "            \n",
    "            for pub in publications:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid not in seen_pmids:\n",
    "                        seen_pmids.add(pmid)\n",
    "                        unique_publications.append(pub)\n",
    "                    else:\n",
    "                        print(f\"Duplicate PMID found in {cell_line_key}: {pmid}\")\n",
    "                        duplicates_found += 1\n",
    "                else:\n",
    "                    # Keep publications without PMID field\n",
    "                    unique_publications.append(pub)\n",
    "            \n",
    "            # Update the publications list\n",
    "            cell_line_data['publications'] = unique_publications\n",
    "            total_publications_after += len(unique_publications)\n",
    "            \n",
    "            # Report if duplicates were removed for this cell line\n",
    "            if len(unique_publications) < original_count:\n",
    "                print(f\"  Removed {original_count - len(unique_publications)} duplicate(s) from {cell_line_key}\")\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total duplicates found and removed: {duplicates_found}\")\n",
    "    print(f\"Total publications before: {total_publications_before}\")\n",
    "    print(f\"Total publications after: {total_publications_after}\")\n",
    "    print(f\"Publications reduced by: {total_publications_before - total_publications_after}\")\n",
    "    \n",
    "    return gt_data\n",
    "\n",
    "# Apply the deduplication\n",
    "gt_data = remove_duplicate_publications(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_line_key, cell_line_data in gt_data.items():\n",
    "    if len(cell_line_data[\"publications\"]) == 1 and cell_line_data['publications'][0]['pmid'] == \"Missing\":\n",
    "        print(cell_line_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a dictionary mapping PMIDs to cell line data\n",
    "def create_pmid_to_celllines_mapping(gt_data):\n",
    "    \"\"\"\n",
    "    Create a dictionary where:\n",
    "    - Keys: PMIDs (excluding \"Missing\")\n",
    "    - Values: List of cell line data objects that have publications with that PMID\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Get all unique PMIDs (excluding \"Missing\")\n",
    "    all_pmids = set()\n",
    "\n",
    "    for cell_line_key, cell_line_data in gt_data.items():\n",
    "        if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "            for pub in cell_line_data['publications']:\n",
    "                if isinstance(pub, dict) and 'pmid' in pub:\n",
    "                    pmid = pub['pmid']\n",
    "                    if pmid != \"Missing\" and pmid is not None:\n",
    "                        all_pmids.add(pmid)\n",
    "\n",
    "    print(f\"Found {len(all_pmids)} unique PMIDs (excluding 'Missing')\")\n",
    "\n",
    "    # Step 2: Create mapping from PMID to cell lines\n",
    "    pmid_to_celllines = {}\n",
    "\n",
    "    for pmid in all_pmids:\n",
    "        pmid_to_celllines[pmid] = []\n",
    "\n",
    "        # Find all cell lines that have this PMID\n",
    "        for cell_line_key, cell_line_data in gt_data.items():\n",
    "            if 'publications' in cell_line_data and isinstance(cell_line_data['publications'], list):\n",
    "                # Check if this cell line has a publication with this PMID\n",
    "                has_pmid = False\n",
    "                for pub in cell_line_data['publications']:\n",
    "                    if isinstance(pub, dict) and 'pmid' in pub and pub['pmid'] == pmid:\n",
    "                        has_pmid = True\n",
    "                        break\n",
    "\n",
    "                if has_pmid:\n",
    "                    # Add the entire cell line data object\n",
    "                    pmid_to_celllines[pmid].append({\n",
    "                        'cell_line_id': cell_line_key,\n",
    "                        'data': cell_line_data\n",
    "                    })\n",
    "\n",
    "    # Step 3: Print summary statistics\n",
    "    print(f\"\\nPMID to Cell Lines Mapping Summary:\")\n",
    "    print(f\"Total unique PMIDs: {len(pmid_to_celllines)}\")\n",
    "\n",
    "    # Show distribution of how many cell lines per PMID\n",
    "    cellline_counts = [len(cell_lines) for cell_lines in pmid_to_celllines.values()]\n",
    "    from collections import Counter\n",
    "    count_distribution = Counter(cellline_counts)\n",
    "\n",
    "    print(f\"Distribution of cell lines per PMID:\")\n",
    "    for count, frequency in sorted(count_distribution.items()):\n",
    "        print(f\"  {count} cell line(s): {frequency} PMID(s)\")\n",
    "\n",
    "    # Show examples of PMIDs with multiple cell lines\n",
    "    multi_cellline_pmids = {pmid: cell_lines for pmid, cell_lines in pmid_to_celllines.items() if len(cell_lines) > 1}\n",
    "    if multi_cellline_pmids:\n",
    "        print(f\"\\nExample PMIDs with multiple cell lines:\")\n",
    "        for pmid, cell_lines in list(multi_cellline_pmids.items())[:5]:\n",
    "            cell_line_ids = [cl['cell_line_id'] for cl in cell_lines]\n",
    "            print(f\"  PMID {pmid}: {cell_line_ids}\")\n",
    "\n",
    "    return pmid_to_celllines\n",
    "\n",
    "# Create the mapping\n",
    "pmid_to_celllines = create_pmid_to_celllines_mapping(gt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell lines journals lists\n",
    "\n",
    "# It gives a list of cell lines and journals they are published in, where we have the journal information\n",
    "# So we are excluding cell lines which don't have journal information. \n",
    "# I need to know and want to report on which journal it came from.\n",
    "cell_line_journals = dict()\n",
    "\n",
    "for cell_line_key, cell_line_data in gt_data.items():\n",
    "    journals = []\n",
    "    for pub in cell_line_data[\"publications\"]:\n",
    "        if \"journal\" in pub and pub[\"journal\"] != \"Missing\":\n",
    "            journals.append(pub[\"journal\"])\n",
    "    cell_line_journals[cell_line_key] = journals\n",
    "\n",
    "\n",
    "# Should include the hypothesis about structured reporting increases the performance of the curation process.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell lines which appear in more than one journal\n",
    "\n",
    "more_than_one_journal = [cell_line for cell_line, journals in cell_line_journals.items() if len(journals) > 1]\n",
    "\n",
    "print(len(more_than_one_journal))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell lines which appear in exactly one journal\n",
    "exactly_one_journal = [cell_line for cell_line, journals in cell_line_journals.items() if len(journals) == 1]   \n",
    "print(len(exactly_one_journal))\n",
    " \n",
    "\n",
    "# Get the set of unique journal names for cell lines that appear in exactly one journal, ignoring case\n",
    "unique_journals = set()\n",
    "journal_name_map = dict()  # maps lowercased journal name to original for display\n",
    "\n",
    "for cell_line in exactly_one_journal:\n",
    "    journals = cell_line_journals[cell_line]\n",
    "    if journals:  # should always be length 1, but check anyway\n",
    "        journal_lower = journals[0].lower()\n",
    "        unique_journals.add(journal_lower)\n",
    "        # Store the first encountered original-case version for display\n",
    "        if journal_lower not in journal_name_map:\n",
    "            journal_name_map[journal_lower] = journals[0]\n",
    "\n",
    "print(len(unique_journals))\n",
    "\n",
    "# Display the unique journals in their original case (first encountered)\n",
    "from pprint import pprint\n",
    "pprint([journal_name_map[j] for j in unique_journals])\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Count how many cell lines are associated with each journal (for cell lines in exactly one journal), ignoring case\n",
    "journal_counts = Counter()\n",
    "for cell_line in exactly_one_journal:\n",
    "    journals = cell_line_journals[cell_line]\n",
    "    if journals:  # should always be length 1\n",
    "        journal_lower = journals[0].lower()\n",
    "        journal_counts[journal_lower] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the counts\n",
    "for journal, count in journal_counts.items():\n",
    "    print(f\"{journal}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "113 cell lines from SCR\n",
    "28 cell lines from non-SCR\n",
    "\n",
    "\n",
    "Why did you only take cell lines which were associated with exactly one journal?\n",
    "Because I could not tell which journal article the data in the registry was associated with. So i needed to be sure that the data was from a specific publication, from a specific journal. So that I could run the automated curation on this publication and be sure that I had the right ground truth to compare my results to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(exactly_one_journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_pmids = [] \n",
    "for cell_line in exactly_one_journal:\n",
    "    pmid = gt_data[cell_line][\"publications\"][0][\"pmid\"]\n",
    "    if pmid != \"Missing\":\n",
    "        ground_truth_pmids.append(pmid)\n",
    "\n",
    "pprint(ground_truth_pmids)\n",
    "print(len(ground_truth_pmids))\n",
    "\n",
    "\n",
    "# These are the pmids I need to run the automated curation on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Also get the journal name for the pmid\n",
    "\n",
    "ground_truth_pmid_journals = []\n",
    "for cell_line in exactly_one_journal:\n",
    "    pmid = gt_data[cell_line][\"publications\"][0][\"pmid\"]\n",
    "    journal = gt_data[cell_line][\"publications\"][0].get(\"journal\", None)\n",
    "    if pmid != \"Missing\":\n",
    "        ground_truth_pmid_journals.append({\"pmid\": pmid, \"journal\": journal})\n",
    "\n",
    "pprint(ground_truth_pmid_journals)\n",
    "print(len(ground_truth_pmid_journals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright. I got the files I need to curate. Now I need to curate them.\n",
    "\n",
    "# Test 1. Curate a single file.\n",
    "\n",
    "\n",
    "# Test 2. Curate every file.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Things to watch out for.\n",
    "- When batch curating. I need a report of the curation session.\n",
    "- Professional logging. To a loglife.\n",
    "- Let's do it.\n",
    "\n",
    "\n",
    "What needs to be written in the report about this. \n",
    "- Report on the curation instructions and how they were used.\n",
    "\n",
    "Also need to write the scoring function next. Tomorrow. After everything is done.\n",
    "Also need to write the nature news essay. But I don't particularly care about the marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stefan-masters-research",
   "language": "python",
   "name": "stefan-masters-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
